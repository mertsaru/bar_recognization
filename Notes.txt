What are the reliability of the functions?

What are the reliability of the globin radiuses?

What is the reliability of the lines that functions find?

Check the reliability of the images visually or by function.
Run through all the dataset, not only A-kapp

Try to find use for find bar sharp functions.
maybe they can detect lines that smooth or dent misses
but threat the lines that sharp finds seperately

If Sharp and dent+smooth can work together, mayke line elimination(or validating the file) would be better.

find the main differce from alpha 1 to bottom

'''
We need to read from top to bottom all the lines and highlight the big changes.
should check increase and decrease(or is just one enough?).

and need delta value to draw the line with which density we are accepting to draw the line
(we havent chose an epsilon so delta can be named as epsilon for now. It is the epsilon idea.)
small delta would be better than a big one.
density wont be close to white since some lines have small blue bars in between. but delta should avoid 
detecting the individual diffrences in a single line.

for now we can use hand-chosen delta like we did on 
epsilon, but we need a better way to choose delta and epsilon, besides bar width and height.
bar width and height can be entered manually but delta epsilon should be generated by variance or some stuff.

With some of the lines, its hard to detect the sudden change. What should we take epsilon?
Or should we use threshold again? same or a different threshold? Or both?

Checking epsilon values from fixed point to the rest of the rows might be a good idea to use epsilon.
Look for increase and decrease. When it becomes epsilon near itself again? Take mid point of those.'''

## drawing lines to each change
'''
What if the loop detects last couple of lines as an end of a bar? We can draw it manually, we do not need to include in the loop.
also if we do it manually and loop also detects, then we have two lines close to each other, which represents the same point.
'''
'''
# Storing indeces as original uncutted img version.

lines = [top_row_index] # starting with the top line
i = 0
while i < (bottom_row_index - top_row_index):
    
    starting i and j fresh from 0, since we are using cutted version of the bar, so it will take less calculation time.
    But we are storing indices as original version, since at the end, we are implementing these lines on the full image version.
    Should we store indices with the original version? It would be better if we use cutted.
    
    row_start_val = row_vals[i]
    
    for j in range(i +1 , bottom_row_index - top_row_index):
        line_end_val = row_vals[j]
        
        if abs(row_start_val - line_end_val) > epsilon:
            lines.append(top_row_index +j) 
            i = j # skip to the j^th row to start comparing below rows.
            break
else:
    lines.append(bottom_row_index) #ending the line list with the bottom line of the graph'''
'''
take lines into a list. we need n many lines. if we have more take first n many, if we have less then dont take that data as a approximator.
'''

